{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_cols = [\n",
    "    'B01001A_001E',\n",
    "    'B01001_001E',\n",
    "    'B01002_001E',\n",
    "    'B19013_001E',\n",
    "    'B19301_001E',\n",
    "    'B23020_001E',\n",
    "    'B25058_001E',\n",
    "    'B25105_001E',\n",
    "    'B25071_001E',\n",
    "    'B24031_003E',\n",
    "    'B24031_004E',\n",
    "    'B24031_005E',\n",
    "    'B24031_006E',\n",
    "    'B24031_007E',\n",
    "    'B24031_008E',\n",
    "    'B24031_010E',\n",
    "    'B24031_011E',\n",
    "    'B24031_012E',\n",
    "    'B24031_014E',\n",
    "    'B24031_015E',\n",
    "    'B24031_017E',\n",
    "    'B24031_018E',\n",
    "    'B24031_019E',\n",
    "    'B24031_021E',\n",
    "    'B24031_022E',\n",
    "    'B24031_024E',\n",
    "    'B24031_025E',\n",
    "    'B24031_026E',\n",
    "    'B24031_027E',\n",
    "    'B12006_004E',\n",
    "    'B12006_009E',\n",
    "    'B12006_015E',\n",
    "    'B12006_020E',\n",
    "    'B12006_026E',\n",
    "    'B12006_031E',\n",
    "    'B12006_037E',\n",
    "    'B12006_042E',\n",
    "    'B12006_048E',\n",
    "    'B12006_053E',\n",
    "    'B12006_006E',\n",
    "    'B12006_011E',\n",
    "    'B12006_017E',\n",
    "    'B12006_022E',\n",
    "    'B12006_028E',\n",
    "    'B12006_033E',\n",
    "    'B12006_039E',\n",
    "    'B12006_044E',\n",
    "    'B12006_050E',\n",
    "    'B12006_055E',\n",
    "    'B15002_001E',\n",
    "    'B15002_004E',\n",
    "    'B15002_005E',\n",
    "    'B15002_006E',\n",
    "    'B15002_007E',\n",
    "    'B15002_008E',\n",
    "    'B15002_009E',\n",
    "    'B15002_010E',\n",
    "    'B15002_011E',\n",
    "    'B15002_012E',\n",
    "    'B15002_013E',\n",
    "    'B15002_014E',\n",
    "    'B15002_015E',\n",
    "    'B15002_016E',\n",
    "    'B15002_017E',\n",
    "    'B15002_018E',\n",
    "    'B15002_021E',\n",
    "    'B15002_022E',\n",
    "    'B15002_023E',\n",
    "    'B15002_024E',\n",
    "    'B15002_025E',\n",
    "    'B15002_026E',\n",
    "    'B15002_027E',\n",
    "    'B15002_028E',\n",
    "    'B15002_029E',\n",
    "    'B15002_030E',\n",
    "    'B15002_031E',\n",
    "    'B15002_032E',\n",
    "    'B15002_033E',\n",
    "    'B15002_034E',\n",
    "    'B15002_035E',\n",
    "    'B15002_020E',\n",
    "    'B15002_003E',\n",
    "    'B08303_002E',\n",
    "    'B08303_003E',\n",
    "    'B08303_004E',\n",
    "    'B08303_005E',\n",
    "    'B08303_006E',\n",
    "    'B08303_007E',\n",
    "    'B08303_008E',\n",
    "    'B08303_009E',\n",
    "    'B08303_010E',\n",
    "    'B08303_011E',\n",
    "    'B08303_012E',\n",
    "    'B08303_013E',\n",
    "    'B08303_001E',\n",
    "]\n",
    "\n",
    "geo_cols = [\n",
    "    'NAME',\n",
    "    'GEO_ID',\n",
    "    'STATE',\n",
    "    'COUNTY',\n",
    "    'REGION',\n",
    "    'PLACE',\n",
    "    'SUMLEVEL',\n",
    "    'UA',\n",
    "    'CBSA'\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt #0\n",
      "attempt #0\n",
      "attempt #0\n",
      "attempt #0\n",
      "attempt #0\n",
      "attempt #0\n",
      "attempt #0\n",
      "attempt #0\n",
      "attempt #0\n",
      "attempt #0\n",
      "attempt #0\n",
      "attempt #0\n",
      "attempt #0\n",
      "attempt #0\n",
      "attempt #0\n",
      "attempt #0\n",
      "attempt #0\n",
      "attempt #0\n",
      "attempt #0\n",
      "attempt #0\n",
      "attempt #0\n",
      "attempt #0\n",
      "attempt #0\n",
      "attempt #0\n",
      "attempt #0\n",
      "attempt #0\n",
      "attempt #0\n",
      "attempt #0\n",
      "attempt #0\n",
      "attempt #0\n",
      "attempt #0\n",
      "attempt #0\n",
      "attempt #0\n",
      "attempt #0\n",
      "attempt #0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://api.census.gov/data/{year}/acs/acs5?get={fields}&for={geo}:*&key={key}'\n",
    "# geo = 'state'\n",
    "# year = 2009\n",
    "\n",
    "geos = [\n",
    "    ('state','state'),\n",
    "    ('county','county'),\n",
    "    ('place','place'),\n",
    "    ('metro', 'metropolitan statistical area/micropolitan statistical area')\n",
    "]\n",
    "\n",
    "years = list(range(2009,2021))\n",
    "# years = [2021]\n",
    "\n",
    "files = os.listdir('data')\n",
    "\n",
    "with open('filters.json', 'r') as f:\n",
    "    filters = json.load(f)\n",
    "\n",
    "def divide_chunks(l, n):\n",
    "     \n",
    "    # looping till length l\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "\n",
    "# filtered = list(set(api_cols) - set(filters.get(str(year),[])))\n",
    "# field_groups = [geo_cols + x for x in list(divide_chunks(filtered,40))]\n",
    "\n",
    "\n",
    "for year in years:\n",
    "    filtered = list(set(api_cols) - set(filters.get(str(year),[])))\n",
    "    field_groups = [geo_cols + x for x in list(divide_chunks(filtered,40))]\n",
    "    for geo in geos[3:]:\n",
    "        if f'{geo[0]}_{year}_census_api.csv' not in files:\n",
    "            base_df = None\n",
    "            for group in field_groups:\n",
    "                count = 0\n",
    "                error = True\n",
    "                while error and count < 200:\n",
    "                    error = False\n",
    "                    print(f'attempt #{count}')\n",
    "                    count += 1\n",
    "                    key = 'c8763b1f3e686c707cf581321b8c16152e9d30e3'\n",
    "                    filtered_cols = list(set(group) - set(filters.get(str(year),[])))\n",
    "                    fields = ','.join(filtered_cols)\n",
    "                    formatted_url = url.format(year=year, fields=fields, geo=geo[1], key=key)\n",
    "\n",
    "                    x = requests.get(formatted_url)\n",
    "\n",
    "\n",
    "\n",
    "                    if x.status_code == 400 and 'error: error: unknown variable ' in x.text:\n",
    "                        bad_var = x.text.replace('error: error: unknown variable ','').replace(\"'\",'')\n",
    "                        filters[str(year)] = filters.get(str(year),[]) + [bad_var]\n",
    "                        with open('filters.json', 'w') as f:\n",
    "                            json.dump(filters, f, indent=4)\n",
    "\n",
    "\n",
    "                    # print(formatted_url)\n",
    "                    # print(x.status_code)\n",
    "                    \n",
    "                    if x.status_code == 200:\n",
    "                        try:\n",
    "                            data = x.json()\n",
    "                        except:\n",
    "                            error = True\n",
    "                            print(f'failed to parse json')\n",
    "                    else:\n",
    "                        error = True\n",
    "                        print(f'failed with code: {x.status_code}')\n",
    "\n",
    "                    # print(x.text)\n",
    "\n",
    "                tmp_df = pd.DataFrame(data[1:],columns=data[0],).set_index('GEO_ID')\n",
    "                if base_df is None:\n",
    "                    base_df = tmp_df\n",
    "                else:\n",
    "                    cols_to_use = tmp_df.columns.difference(base_df.columns)\n",
    "                    base_df = base_df.join(tmp_df[cols_to_use])\n",
    "                # print(base_df.head())\n",
    "\n",
    "            base_df['year'] = year\n",
    "            base_df['geo_type'] = geo[0]\n",
    "            base_df.to_csv(f'data/{geo[0]}_{year}_census_api.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['metro_2018_census_api.csv', 'county_2016_census_api.csv', 'processed', 'metro_2012_census_api.csv', 'state_2009_census_api.csv', 'metro_2014_census_api.csv', 'state_2010_census_api.csv', 'backup', 'place_2015_census_api.csv', 'place_2020_census_api.csv', 'state_2015_census_api.csv', 'state_2017_census_api.csv', 'county_2014_census_api.csv', 'metro_2011_census_api.csv', 'metro_2009_census_api.csv', 'state_2013_census_api.csv', 'place_2017_census_api.csv', 'county_2017_census_api.csv', 'metro_2020_census_api.csv', 'metro_2010_census_api.csv', 'place_2009_census_api.csv', 'place_2018_census_api.csv', 'metro_2015_census_api.csv', 'state_2019_census_api.csv', 'metro_2016_census_api.csv', 'place_2014_census_api.csv', 'state_2011_census_api.csv', 'state_2016_census_api.csv', 'county_2012_census_api.csv', 'place_2011_census_api.csv', 'county_2013_census_api.csv', 'metro_2019_census_api.csv', 'county_2010_census_api.csv', 'county_2015_census_api.csv', 'place_2019_census_api.csv', 'metro_2013_census_api.csv', 'place_2021_census_api.csv', 'metro_2017_census_api.csv', 'state_2021_census_api.csv', 'place_2016_census_api.csv', 'place_2013_census_api.csv', 'county_2011_census_api.csv', 'state_2012_census_api.csv', 'county_2020_census_api.csv', 'state_2020_census_api.csv', 'county_2019_census_api.csv', 'place_2010_census_api.csv', 'state_2018_census_api.csv', 'county_2021_census_api.csv', 'county_2009_census_api.csv', 'county_2018_census_api.csv', 'metro_2021_census_api.csv', 'place_2012_census_api.csv', 'state_2014_census_api.csv']\n",
      "metro_2018_census_api.csv\n",
      "{'SUMLEVEL'}\n",
      "state_2009_census_api.csv\n",
      "{'B23020_001E', 'B25105_001E', 'B12006_031E', 'B12006_004E', 'B24031_021E', 'B24031_026E', 'B24031_011E', 'B12006_053E', 'B24031_010E', 'B24031_018E', 'B12006_042E', 'B24031_027E', 'B24031_007E', 'B24031_024E', 'B12006_033E', 'B12006_015E', 'B12006_028E', 'B24031_022E', 'B12006_039E', 'B12006_022E', 'B24031_017E', 'B24031_025E', 'B24031_004E', 'B12006_050E', 'B24031_008E', 'B12006_048E', 'B24031_003E', 'B12006_044E', 'B24031_005E', 'B12006_037E', 'B12006_009E', 'B12006_026E', 'B12006_006E', 'B12006_020E', 'B24031_012E', 'B24031_006E', 'B12006_017E', 'B24031_014E', 'B24031_019E', 'B12006_055E', 'B24031_015E', 'B12006_011E'}\n",
      "state_2017_census_api.csv\n",
      "{'SUMLEVEL'}\n",
      "metro_2009_census_api.csv\n",
      "{'B23020_001E', 'B25105_001E', 'B12006_031E', 'B12006_004E', 'B24031_021E', 'B24031_026E', 'B24031_011E', 'B12006_053E', 'B24031_010E', 'B24031_018E', 'B12006_042E', 'B24031_027E', 'B24031_007E', 'B24031_024E', 'B12006_033E', 'B12006_015E', 'B12006_028E', 'B24031_022E', 'B12006_039E', 'B12006_022E', 'B24031_017E', 'B24031_025E', 'B24031_004E', 'B12006_050E', 'B24031_008E', 'B12006_048E', 'B24031_003E', 'B12006_044E', 'B24031_005E', 'B12006_037E', 'B12006_009E', 'B12006_026E', 'B12006_006E', 'B12006_020E', 'B24031_012E', 'B24031_006E', 'B12006_017E', 'B24031_014E', 'B24031_019E', 'B12006_055E', 'B24031_015E', 'B12006_011E'}\n",
      "place_2017_census_api.csv\n",
      "{'SUMLEVEL'}\n",
      "county_2017_census_api.csv\n",
      "{'SUMLEVEL'}\n",
      "place_2009_census_api.csv\n",
      "{'B23020_001E', 'B25105_001E', 'B12006_031E', 'B12006_004E', 'B24031_021E', 'B24031_026E', 'B24031_011E', 'B12006_053E', 'B24031_010E', 'B24031_018E', 'B12006_042E', 'B24031_027E', 'B24031_007E', 'B24031_024E', 'B12006_033E', 'B12006_015E', 'B12006_028E', 'B24031_022E', 'B12006_039E', 'B12006_022E', 'B24031_017E', 'B24031_025E', 'B24031_004E', 'B12006_050E', 'B24031_008E', 'B12006_048E', 'B24031_003E', 'B12006_044E', 'B24031_005E', 'B12006_037E', 'B12006_009E', 'B12006_026E', 'B12006_006E', 'B12006_020E', 'B24031_012E', 'B24031_006E', 'B12006_017E', 'B24031_014E', 'B24031_019E', 'B12006_055E', 'B24031_015E', 'B12006_011E'}\n",
      "place_2018_census_api.csv\n",
      "{'SUMLEVEL'}\n",
      "metro_2017_census_api.csv\n",
      "{'SUMLEVEL'}\n",
      "state_2018_census_api.csv\n",
      "{'SUMLEVEL'}\n",
      "county_2009_census_api.csv\n",
      "{'B23020_001E', 'B25105_001E', 'B12006_031E', 'B12006_004E', 'B24031_021E', 'B24031_026E', 'B24031_011E', 'B12006_053E', 'B24031_010E', 'B24031_018E', 'B12006_042E', 'B24031_027E', 'B24031_007E', 'B24031_024E', 'B12006_033E', 'B12006_015E', 'B12006_028E', 'B24031_022E', 'B12006_039E', 'B12006_022E', 'B24031_017E', 'B24031_025E', 'B24031_004E', 'B12006_050E', 'B24031_008E', 'B12006_048E', 'B24031_003E', 'B12006_044E', 'B24031_005E', 'B12006_037E', 'B12006_009E', 'B12006_026E', 'B12006_006E', 'B12006_020E', 'B24031_012E', 'B24031_006E', 'B12006_017E', 'B24031_014E', 'B24031_019E', 'B12006_055E', 'B24031_015E', 'B12006_011E'}\n",
      "county_2018_census_api.csv\n",
      "{'SUMLEVEL'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "files = os.listdir('data')\n",
    "print(files)\n",
    "exp_len = len(geo_cols) + len(api_cols)\n",
    "\n",
    "exp_cols = set(geo_cols + api_cols)\n",
    "\n",
    "for file in files:\n",
    "    if 'processed' not in file and 'backup' not in file:\n",
    "        df = pd.read_csv('data/' + file, nrows = 5)\n",
    "        # if len(df.columns) < exp_len:\n",
    "        # print(file)\n",
    "        # print(file+':',len(df.columns),'/',exp_len)\n",
    "        diff = exp_cols - set(df.columns)\n",
    "        if diff:\n",
    "            print(file)\n",
    "            print(diff)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
